{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f137398e",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 使用块的网络（VGG）\n",
    ":label:`sec_vgg`\n",
    "\n",
    "虽然AlexNet证明深层神经网络卓有成效，但它没有提供一个通用的模板来指导后续的研究人员设计新的网络。\n",
    "在下面的几个章节中，我们将介绍一些常用于设计深层神经网络的启发式概念。\n",
    "\n",
    "与芯片设计中工程师从放置晶体管到逻辑元件再到逻辑块的过程类似，神经网络架构的设计也逐渐变得更加抽象。研究人员开始从单个神经元的角度思考问题，发展到整个层，现在又转向块，重复层的模式。\n",
    "\n",
    "使用块的想法首先出现在牛津大学的[视觉几何组（visual geometry group）](http://www.robots.ox.ac.uk/~vgg/)的*VGG网络*中。通过使用循环和子程序，可以很容易地在任何现代深度学习框架的代码中实现这些重复的架构。\n",
    "\n",
    "## (**VGG块**)\n",
    "\n",
    "经典卷积神经网络的基本组成部分是下面的这个序列：\n",
    "\n",
    "1. 带填充以保持分辨率的卷积层；\n",
    "1. 非线性激活函数，如ReLU；\n",
    "1. 汇聚层，如最大汇聚层。\n",
    "\n",
    "而一个VGG块与之类似，由一系列卷积层组成，后面再加上用于空间下采样的最大汇聚层。在最初的VGG论文中 :cite:`Simonyan.Zisserman.2014`，作者使用了带有$3\\times3$卷积核、填充为1（保持高度和宽度）的卷积层，和带有$2 \\times 2$汇聚窗口、步幅为2（每个块后的分辨率减半）的最大汇聚层。在下面的代码中，我们定义了一个名为`vgg_block`的函数来实现一个VGG块。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace41ffc",
   "metadata": {
    "origin_pos": 1,
    "tab": [
     "tensorflow"
    ]
   },
   "source": [
    "该函数有两个参数，分别对应于卷积层的数量`num_convs`和输出通道的数量`num_channels`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5eef61c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:03:09.397698Z",
     "iopub.status.busy": "2023-08-18T07:03:09.397021Z",
     "iopub.status.idle": "2023-08-18T07:03:12.286902Z",
     "shell.execute_reply": "2023-08-18T07:03:12.286029Z"
    },
    "origin_pos": 5,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from d2l import tensorflow as d2l\n",
    "\n",
    "\n",
    "def vgg_block(num_convs, num_channels):\n",
    "    blk = tf.keras.models.Sequential()\n",
    "    for _ in range(num_convs):\n",
    "        blk.add(tf.keras.layers.Conv2D(num_channels,kernel_size=3,\n",
    "                                    padding='same',activation='relu'))\n",
    "    blk.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a84932",
   "metadata": {
    "origin_pos": 7
   },
   "source": [
    "## [**VGG网络**]\n",
    "\n",
    "与AlexNet、LeNet一样，VGG网络可以分为两部分：第一部分主要由卷积层和汇聚层组成，第二部分由全连接层组成。如 :numref:`fig_vgg`中所示。\n",
    "\n",
    "![从AlexNet到VGG，它们本质上都是块设计。](../img/vgg.svg)\n",
    ":width:`400px`\n",
    ":label:`fig_vgg`\n",
    "\n",
    "VGG神经网络连接 :numref:`fig_vgg`的几个VGG块（在`vgg_block`函数中定义）。其中有超参数变量`conv_arch`。该变量指定了每个VGG块里卷积层个数和输出通道数。全连接模块则与AlexNet中的相同。\n",
    "\n",
    "原始VGG网络有5个卷积块，其中前两个块各有一个卷积层，后三个块各包含两个卷积层。\n",
    "第一个模块有64个输出通道，每个后续模块将输出通道数量翻倍，直到该数字达到512。由于该网络使用8个卷积层和3个全连接层，因此它通常被称为VGG-11。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eaa3cac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:03:12.291498Z",
     "iopub.status.busy": "2023-08-18T07:03:12.290746Z",
     "iopub.status.idle": "2023-08-18T07:03:12.399456Z",
     "shell.execute_reply": "2023-08-18T07:03:12.398621Z"
    },
    "origin_pos": 8,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b92aa2e",
   "metadata": {
    "origin_pos": 9
   },
   "source": [
    "下面的代码实现了VGG-11。可以通过在`conv_arch`上执行for循环来简单实现。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e215ea3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:03:12.403249Z",
     "iopub.status.busy": "2023-08-18T07:03:12.402682Z",
     "iopub.status.idle": "2023-08-18T07:03:15.703907Z",
     "shell.execute_reply": "2023-08-18T07:03:15.702989Z"
    },
    "origin_pos": 12,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 15:23:29.445793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-18 15:23:29.453498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-18 15:23:29.455264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-18 15:23:29.457543: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-18 15:23:29.457964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-18 15:23:29.459641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-18 15:23:29.461259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-18 15:23:29.992008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-18 15:23:29.993109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-18 15:23:29.994075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-18 15:23:29.995248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1940 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "def vgg(conv_arch):\n",
    "    net = tf.keras.models.Sequential()\n",
    "    # 卷积层部分\n",
    "    for (num_convs, num_channels) in conv_arch:\n",
    "        net.add(vgg_block(num_convs, num_channels))\n",
    "    # 全连接层部分\n",
    "    net.add(tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(4096, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(4096, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10)]))\n",
    "    return net\n",
    "\n",
    "net = vgg(conv_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14356cd0",
   "metadata": {
    "origin_pos": 14
   },
   "source": [
    "接下来，我们将构建一个高度和宽度为224的单通道数据样本，以[**观察每个层输出的形状**]。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e4fd9cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:03:15.708180Z",
     "iopub.status.busy": "2023-08-18T07:03:15.707543Z",
     "iopub.status.idle": "2023-08-18T07:03:17.273709Z",
     "shell.execute_reply": "2023-08-18T07:03:17.272829Z"
    },
    "origin_pos": 17,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 15:23:30.470076: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t (1, 112, 112, 64)\n",
      "Sequential output shape:\t (1, 56, 56, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 15:23:31.640927: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2025-04-18 15:23:31.640964: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2025-04-18 15:23:31.836350: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2025-04-18 15:23:31.836388: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t (1, 28, 28, 256)\n",
      "Sequential output shape:\t (1, 14, 14, 512)\n",
      "Sequential output shape:\t (1, 7, 7, 512)\n",
      "Sequential output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "X = tf.random.uniform((1, 224, 224, 1))\n",
    "for blk in net.layers:\n",
    "    X = blk(X)\n",
    "    print(blk.__class__.__name__,'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5682f9b7",
   "metadata": {
    "origin_pos": 19
   },
   "source": [
    "正如从代码中所看到的，我们在每个块的高度和宽度减半，最终高度和宽度都为7。最后再展平表示，送入全连接层处理。\n",
    "\n",
    "## 训练模型\n",
    "\n",
    "[**由于VGG-11比AlexNet计算量更大，因此我们构建了一个通道数较少的网络**]，足够用于训练Fashion-MNIST数据集。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a608a97a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:03:17.277599Z",
     "iopub.status.busy": "2023-08-18T07:03:17.277007Z",
     "iopub.status.idle": "2023-08-18T07:03:17.281754Z",
     "shell.execute_reply": "2023-08-18T07:03:17.280972Z"
    },
    "origin_pos": 21,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "ratio = 4\n",
    "small_conv_arch = [(pair[0], pair[1] // ratio) for pair in conv_arch]\n",
    "# 回想一下，这必须是一个将被放入“d2l.train_ch6()”的函数，为了利用我们现有的CPU/GPU设备，这样模型构建/编译需要在strategy.scope()中\n",
    "net = lambda: vgg(small_conv_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0a470c",
   "metadata": {
    "origin_pos": 22
   },
   "source": [
    "除了使用略高的学习率外，[**模型训练**]过程与 :numref:`sec_alexnet`中的AlexNet类似。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "535c4b30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:03:17.285304Z",
     "iopub.status.busy": "2023-08-18T07:03:17.284768Z",
     "iopub.status.idle": "2023-08-18T07:06:51.303475Z",
     "shell.execute_reply": "2023-08-18T07:06:51.302636Z"
    },
    "origin_pos": 23,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 15:23:32.803435: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 60000\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:0\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 28\n",
      "        }\n",
      "        dim {\n",
      "          size: 28\n",
      "        }\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2025-04-18 15:23:33.883655: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 408.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2025-04-18 15:23:33.883689: W tensorflow/core/kernels/gpu_utils.cc:50] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n",
      "2025-04-18 15:23:33.965791: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2025-04-18 15:23:33.965845: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2025-04-18 15:23:34.088754: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 953.13MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2025-04-18 15:23:34.088792: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 953.13MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2025-04-18 15:23:34.089132: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 212.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2025-04-18 15:23:44.389120: W tensorflow/core/common_runtime/bfc_allocator.cc:462] Allocator (GPU_0_bfc) ran out of memory trying to allocate 24.50MiB (rounded to 25690112)requested by op sequential_7/sequential_10/max_pooling2d_7/MaxPool\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2025-04-18 15:23:44.389200: I tensorflow/core/common_runtime/bfc_allocator.cc:1010] BFCAllocator dump for GPU_0_bfc\n",
      "2025-04-18 15:23:44.389229: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (256): \tTotal Chunks: 67, Chunks in use: 67. 16.8KiB allocated for chunks. 16.8KiB in use in bin. 1.1KiB client-requested in use in bin.\n",
      "2025-04-18 15:23:44.389250: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (512): \tTotal Chunks: 7, Chunks in use: 7. 3.8KiB allocated for chunks. 3.8KiB in use in bin. 3.6KiB client-requested in use in bin.\n",
      "2025-04-18 15:23:44.389269: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1024): \tTotal Chunks: 3, Chunks in use: 2. 3.8KiB allocated for chunks. 2.2KiB in use in bin. 2.0KiB client-requested in use in bin.\n",
      "2025-04-18 15:23:44.389288: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-04-18 15:23:44.389306: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4096): \tTotal Chunks: 1, Chunks in use: 0. 6.8KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-04-18 15:23:44.389323: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-04-18 15:23:44.389344: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16384): \tTotal Chunks: 5, Chunks in use: 5. 86.0KiB allocated for chunks. 86.0KiB in use in bin. 82.0KiB client-requested in use in bin.\n",
      "2025-04-18 15:23:44.389365: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (32768): \tTotal Chunks: 1, Chunks in use: 1. 39.2KiB allocated for chunks. 39.2KiB in use in bin. 39.1KiB client-requested in use in bin.\n",
      "2025-04-18 15:23:44.389387: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (65536): \tTotal Chunks: 3, Chunks in use: 1. 227.0KiB allocated for chunks. 72.0KiB in use in bin. 72.0KiB client-requested in use in bin.\n",
      "2025-04-18 15:23:44.389409: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (131072): \tTotal Chunks: 3, Chunks in use: 3. 526.2KiB allocated for chunks. 526.2KiB in use in bin. 464.0KiB client-requested in use in bin.\n",
      "2025-04-18 15:23:44.389443: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (262144): \tTotal Chunks: 4, Chunks in use: 2. 1.16MiB allocated for chunks. 607.5KiB in use in bin. 522.4KiB client-requested in use in bin.\n",
      "2025-04-18 15:23:44.389472: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (524288): \tTotal Chunks: 4, Chunks in use: 3. 2.66MiB allocated for chunks. 1.69MiB in use in bin. 1.69MiB client-requested in use in bin.\n",
      "2025-04-18 15:23:44.389531: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-04-18 15:23:44.389553: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-04-18 15:23:44.389571: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-04-18 15:23:44.389587: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-04-18 15:23:44.389610: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16777216): \tTotal Chunks: 2, Chunks in use: 1. 45.91MiB allocated for chunks. 29.91MiB in use in bin. 29.91MiB client-requested in use in bin.\n",
      "2025-04-18 15:23:44.389639: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (33554432): \tTotal Chunks: 3, Chunks in use: 3. 127.16MiB allocated for chunks. 127.16MiB in use in bin. 98.00MiB client-requested in use in bin.\n",
      "2025-04-18 15:23:44.389681: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (67108864): \tTotal Chunks: 5, Chunks in use: 5. 447.45MiB allocated for chunks. 447.45MiB in use in bin. 422.00MiB client-requested in use in bin.\n",
      "2025-04-18 15:23:44.389721: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (134217728): \tTotal Chunks: 3, Chunks in use: 3. 531.10MiB allocated for chunks. 531.10MiB in use in bin. 473.44MiB client-requested in use in bin.\n",
      "2025-04-18 15:23:44.389748: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (268435456): \tTotal Chunks: 2, Chunks in use: 2. 784.00MiB allocated for chunks. 784.00MiB in use in bin. 784.00MiB client-requested in use in bin.\n",
      "2025-04-18 15:23:44.389777: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] Bin for 24.50MiB was 16.00MiB, Chunk State: \n",
      "2025-04-18 15:23:44.389830: I tensorflow/core/common_runtime/bfc_allocator.cc:1039]   Size: 16.00MiB | Requested Size: 16.00MiB | in_use: 0 | bin_num: 16, prev:   Size: 29.91MiB | Requested Size: 29.91MiB | in_use: 1 | bin_num: -1, next:   Size: 44.71MiB | Requested Size: 24.50MiB | in_use: 1 | bin_num: -1\n",
      "2025-04-18 15:23:44.389859: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 2034565120\n",
      "2025-04-18 15:23:44.389892: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e000000 of size 256 next 1\n",
      "2025-04-18 15:23:44.389919: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e000100 of size 1280 next 2\n",
      "2025-04-18 15:23:44.389944: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e000600 of size 256 next 11\n",
      "2025-04-18 15:23:44.389968: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e000700 of size 256 next 17\n",
      "2025-04-18 15:23:44.389993: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e000800 of size 256 next 8\n",
      "2025-04-18 15:23:44.390014: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e000900 of size 256 next 25\n",
      "2025-04-18 15:23:44.390036: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e000a00 of size 256 next 20\n",
      "2025-04-18 15:23:44.390058: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e000b00 of size 256 next 21\n",
      "2025-04-18 15:23:44.390078: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e000c00 of size 256 next 24\n",
      "2025-04-18 15:23:44.390094: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e000d00 of size 768 next 26\n",
      "2025-04-18 15:23:44.390107: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e001000 of size 256 next 30\n",
      "2025-04-18 15:23:44.390120: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e001100 of size 256 next 31\n",
      "2025-04-18 15:23:44.390133: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e001200 of size 512 next 78\n",
      "2025-04-18 15:23:44.390146: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e001400 of size 512 next 81\n",
      "2025-04-18 15:23:44.390159: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e001600 of size 512 next 83\n",
      "2025-04-18 15:23:44.390171: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e001800 of size 256 next 85\n",
      "2025-04-18 15:23:44.390184: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e001900 of size 256 next 88\n",
      "2025-04-18 15:23:44.390197: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e001a00 of size 256 next 89\n",
      "2025-04-18 15:23:44.390209: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e001b00 of size 256 next 90\n",
      "2025-04-18 15:23:44.390222: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e001c00 of size 256 next 92\n",
      "2025-04-18 15:23:44.390235: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e001d00 of size 256 next 94\n",
      "2025-04-18 15:23:44.390247: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e001e00 of size 256 next 95\n",
      "2025-04-18 15:23:44.390266: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e001f00 of size 256 next 96\n",
      "2025-04-18 15:23:44.390288: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e002000 of size 256 next 97\n",
      "2025-04-18 15:23:44.390311: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e002100 of size 256 next 98\n",
      "2025-04-18 15:23:44.390333: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e002200 of size 256 next 99\n",
      "2025-04-18 15:23:44.390354: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e002300 of size 256 next 100\n",
      "2025-04-18 15:23:44.390367: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e002400 of size 256 next 101\n",
      "2025-04-18 15:23:44.390379: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e002500 of size 256 next 102\n",
      "2025-04-18 15:23:44.390392: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e002600 of size 256 next 103\n",
      "2025-04-18 15:23:44.390405: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e002700 of size 256 next 104\n",
      "2025-04-18 15:23:44.390417: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e002800 of size 512 next 37\n",
      "2025-04-18 15:23:44.390430: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e002a00 of size 256 next 51\n",
      "2025-04-18 15:23:44.390442: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e002b00 of size 256 next 56\n",
      "2025-04-18 15:23:44.390456: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e002c00 of size 256 next 58\n",
      "2025-04-18 15:23:44.390479: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7b451e002d00 of size 1536 next 108\n",
      "2025-04-18 15:23:44.390531: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e003300 of size 512 next 109\n",
      "2025-04-18 15:23:44.390546: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e003500 of size 256 next 111\n",
      "2025-04-18 15:23:44.390559: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e003600 of size 1024 next 112\n",
      "2025-04-18 15:23:44.390572: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7b451e003a00 of size 6912 next 35\n",
      "2025-04-18 15:23:44.390585: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e005500 of size 40192 next 34\n",
      "2025-04-18 15:23:44.390598: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e00f200 of size 16384 next 87\n",
      "2025-04-18 15:23:44.390613: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e013200 of size 20480 next 60\n",
      "2025-04-18 15:23:44.390626: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e018200 of size 18432 next 59\n",
      "2025-04-18 15:23:44.390639: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7b451e01ca00 of size 84992 next 3\n",
      "2025-04-18 15:23:44.390652: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e031600 of size 256 next 4\n",
      "2025-04-18 15:23:44.390665: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e031700 of size 256 next 5\n",
      "2025-04-18 15:23:44.390677: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e031800 of size 256 next 6\n",
      "2025-04-18 15:23:44.390696: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e031900 of size 256 next 7\n",
      "2025-04-18 15:23:44.390719: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e031a00 of size 256 next 12\n",
      "2025-04-18 15:23:44.390741: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e031b00 of size 256 next 13\n",
      "2025-04-18 15:23:44.390764: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e031c00 of size 256 next 32\n",
      "2025-04-18 15:23:44.390788: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e031d00 of size 256 next 14\n",
      "2025-04-18 15:23:44.390803: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e031e00 of size 256 next 10\n",
      "2025-04-18 15:23:44.390816: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e031f00 of size 256 next 18\n",
      "2025-04-18 15:23:44.390829: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e032000 of size 256 next 33\n",
      "2025-04-18 15:23:44.390841: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e032100 of size 256 next 29\n",
      "2025-04-18 15:23:44.390856: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e032200 of size 256 next 28\n",
      "2025-04-18 15:23:44.390877: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e032300 of size 256 next 19\n",
      "2025-04-18 15:23:44.390901: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e032400 of size 256 next 22\n",
      "2025-04-18 15:23:44.390927: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e032500 of size 256 next 23\n",
      "2025-04-18 15:23:44.390946: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e032600 of size 256 next 15\n",
      "2025-04-18 15:23:44.390959: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e032700 of size 256 next 61\n",
      "2025-04-18 15:23:44.390972: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e032800 of size 256 next 62\n",
      "2025-04-18 15:23:44.390985: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e032900 of size 256 next 65\n",
      "2025-04-18 15:23:44.390997: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e032a00 of size 256 next 66\n",
      "2025-04-18 15:23:44.391010: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e032b00 of size 256 next 67\n",
      "2025-04-18 15:23:44.391024: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e032c00 of size 256 next 68\n",
      "2025-04-18 15:23:44.391036: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e032d00 of size 256 next 71\n",
      "2025-04-18 15:23:44.391050: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e032e00 of size 256 next 72\n",
      "2025-04-18 15:23:44.391063: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e032f00 of size 512 next 75\n",
      "2025-04-18 15:23:44.391075: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e033100 of size 256 next 76\n",
      "2025-04-18 15:23:44.391088: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e033200 of size 256 next 77\n",
      "2025-04-18 15:23:44.391101: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e033300 of size 256 next 9\n",
      "2025-04-18 15:23:44.391113: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e033400 of size 256 next 38\n",
      "2025-04-18 15:23:44.391126: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e033500 of size 256 next 39\n",
      "2025-04-18 15:23:44.391139: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e033600 of size 16384 next 40\n",
      "2025-04-18 15:23:44.391152: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e037600 of size 256 next 43\n",
      "2025-04-18 15:23:44.391165: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e037700 of size 256 next 44\n",
      "2025-04-18 15:23:44.391178: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e037800 of size 16384 next 45\n",
      "2025-04-18 15:23:44.391191: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e03b800 of size 256 next 48\n",
      "2025-04-18 15:23:44.391204: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e03b900 of size 256 next 49\n",
      "2025-04-18 15:23:44.391217: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e03ba00 of size 256 next 50\n",
      "2025-04-18 15:23:44.391229: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e03bb00 of size 256 next 54\n",
      "2025-04-18 15:23:44.391242: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e03bc00 of size 256 next 55\n",
      "2025-04-18 15:23:44.391256: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e03bd00 of size 327168 next 52\n",
      "2025-04-18 15:23:44.391271: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e08bb00 of size 227584 next 16\n",
      "2025-04-18 15:23:44.391287: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b451e0c3400 of size 102760448 next 86\n",
      "2025-04-18 15:23:44.391302: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b45242c3400 of size 411041792 next 105\n",
      "2025-04-18 15:23:44.391317: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b453cac3400 of size 205520896 next 106\n",
      "2025-04-18 15:23:44.391332: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b4548ec3400 of size 163217408 next 42\n",
      "2025-04-18 15:23:44.391347: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b4552a6b400 of size 411041792 next 41\n",
      "2025-04-18 15:23:44.391361: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7b456b26b400 of size 73728 next 64\n",
      "2025-04-18 15:23:44.391376: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b456b27d400 of size 73728 next 63\n",
      "2025-04-18 15:23:44.391389: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7b456b28f400 of size 294912 next 70\n",
      "2025-04-18 15:23:44.391403: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b456b2d7400 of size 147456 next 69\n",
      "2025-04-18 15:23:44.391418: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7b456b2fb400 of size 294912 next 74\n",
      "2025-04-18 15:23:44.391432: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b456b343400 of size 294912 next 73\n",
      "2025-04-18 15:23:44.391447: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b456b38b400 of size 163840 next 93\n",
      "2025-04-18 15:23:44.391461: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7b456b3b3400 of size 1015808 next 79\n",
      "2025-04-18 15:23:44.391476: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b456b4ab400 of size 589824 next 80\n",
      "2025-04-18 15:23:44.391514: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b456b53b400 of size 589824 next 82\n",
      "2025-04-18 15:23:44.391541: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b456b5cb400 of size 589824 next 84\n",
      "2025-04-18 15:23:44.391558: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b456b65b400 of size 35071232 next 27\n",
      "2025-04-18 15:23:44.391573: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b456d7cd900 of size 31360000 next 36\n",
      "2025-04-18 15:23:44.391588: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7b456f5b5d00 of size 16777216 next 110\n",
      "2025-04-18 15:23:44.391603: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b45705b5d00 of size 46880512 next 47\n",
      "2025-04-18 15:23:44.391618: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b457326b400 of size 67108864 next 46\n",
      "2025-04-18 15:23:44.391633: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b457726b400 of size 67108864 next 91\n",
      "2025-04-18 15:23:44.391648: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b457b26b400 of size 121051136 next 53\n",
      "2025-04-18 15:23:44.391664: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b45825dcc00 of size 188160000 next 57\n",
      "2025-04-18 15:23:44.391680: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b458d94e400 of size 51380224 next 107\n",
      "2025-04-18 15:23:44.391695: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7b4590a4e400 of size 111156224 next 18446744073709551615\n",
      "2025-04-18 15:23:44.391709: I tensorflow/core/common_runtime/bfc_allocator.cc:1071]      Summary of in-use Chunks by size: \n",
      "2025-04-18 15:23:44.391732: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 67 Chunks of size 256 totalling 16.8KiB\n",
      "2025-04-18 15:23:44.391749: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 6 Chunks of size 512 totalling 3.0KiB\n",
      "2025-04-18 15:23:44.391764: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 768 totalling 768B\n",
      "2025-04-18 15:23:44.391778: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1024 totalling 1.0KiB\n",
      "2025-04-18 15:23:44.391793: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2025-04-18 15:23:44.391809: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 3 Chunks of size 16384 totalling 48.0KiB\n",
      "2025-04-18 15:23:44.391824: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 18432 totalling 18.0KiB\n",
      "2025-04-18 15:23:44.391839: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 20480 totalling 20.0KiB\n",
      "2025-04-18 15:23:44.391855: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 40192 totalling 39.2KiB\n",
      "2025-04-18 15:23:44.391870: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 73728 totalling 72.0KiB\n",
      "2025-04-18 15:23:44.391885: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 147456 totalling 144.0KiB\n",
      "2025-04-18 15:23:44.391900: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 163840 totalling 160.0KiB\n",
      "2025-04-18 15:23:44.391916: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 227584 totalling 222.2KiB\n",
      "2025-04-18 15:23:44.391930: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 294912 totalling 288.0KiB\n",
      "2025-04-18 15:23:44.391945: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 327168 totalling 319.5KiB\n",
      "2025-04-18 15:23:44.391960: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 3 Chunks of size 589824 totalling 1.69MiB\n",
      "2025-04-18 15:23:44.391975: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 31360000 totalling 29.91MiB\n",
      "2025-04-18 15:23:44.391992: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 35071232 totalling 33.45MiB\n",
      "2025-04-18 15:23:44.392009: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 46880512 totalling 44.71MiB\n",
      "2025-04-18 15:23:44.392026: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 51380224 totalling 49.00MiB\n",
      "2025-04-18 15:23:44.392042: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 67108864 totalling 128.00MiB\n",
      "2025-04-18 15:23:44.392059: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 102760448 totalling 98.00MiB\n",
      "2025-04-18 15:23:44.392078: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 111156224 totalling 106.01MiB\n",
      "2025-04-18 15:23:44.392106: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 121051136 totalling 115.44MiB\n",
      "2025-04-18 15:23:44.392138: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 163217408 totalling 155.66MiB\n",
      "2025-04-18 15:23:44.392172: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 188160000 totalling 179.44MiB\n",
      "2025-04-18 15:23:44.392192: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 205520896 totalling 196.00MiB\n",
      "2025-04-18 15:23:44.392209: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 411041792 totalling 784.00MiB\n",
      "2025-04-18 15:23:44.392225: I tensorflow/core/common_runtime/bfc_allocator.cc:1078] Sum Total of in-use chunks: 1.88GiB\n",
      "2025-04-18 15:23:44.392239: I tensorflow/core/common_runtime/bfc_allocator.cc:1080] total_region_allocated_bytes_: 2034565120 memory_limit_: 2034565120 available bytes: 0 curr_region_allocation_bytes_: 4069130240\n",
      "2025-04-18 15:23:44.392263: I tensorflow/core/common_runtime/bfc_allocator.cc:1086] Stats: \n",
      "Limit:                      2034565120\n",
      "InUse:                      2016015104\n",
      "MaxInUse:                   2032939776\n",
      "NumAllocs:                         402\n",
      "MaxAllocSize:               1164574720\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-04-18 15:23:44.392304: W tensorflow/core/common_runtime/bfc_allocator.cc:474] *****************************************xx*********************************************************\n",
      "2025-04-18 15:23:44.392403: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at pooling_ops_common.cc:226 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[128,64,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_7/sequential_10/max_pooling2d_7/MaxPool' defined at (most recent call last):\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n      result = self._run_cell(\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n      result = runner(coro)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_54002/3357625958.py\", line 3, in <module>\n      d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/d2l/tensorflow.py\", line 485, in train_ch6\n      net.fit(train_iter, epochs=num_epochs, verbose=0, callbacks=[callback])\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/layers/pooling.py\", line 357, in call\n      outputs = self.pool_function(\nNode: 'sequential_7/sequential_10/max_pooling2d_7/MaxPool'\nOOM when allocating tensor with shape[128,64,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential_7/sequential_10/max_pooling2d_7/MaxPool}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1853]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m lr, num_epochs, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m128\u001b[39m\n\u001b[1;32m      2\u001b[0m train_iter, test_iter \u001b[38;5;241m=\u001b[39m d2l\u001b[38;5;241m.\u001b[39mload_data_fashion_mnist(batch_size, resize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m224\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43md2l\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_ch6\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md2l\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_gpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/site-packages/d2l/tensorflow.py:485\u001b[0m, in \u001b[0;36mtrain_ch6\u001b[0;34m(net_fn, train_iter, test_iter, num_epochs, lr, device)\u001b[0m\n\u001b[1;32m    482\u001b[0m     net\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39mloss, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    483\u001b[0m callback \u001b[38;5;241m=\u001b[39m TrainCallback(net, train_iter, test_iter, num_epochs,\n\u001b[1;32m    484\u001b[0m                          device_name)\n\u001b[0;32m--> 485\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m net\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_7/sequential_10/max_pooling2d_7/MaxPool' defined at (most recent call last):\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n      result = self._run_cell(\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n      result = runner(coro)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_54002/3357625958.py\", line 3, in <module>\n      d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/d2l/tensorflow.py\", line 485, in train_ch6\n      net.fit(train_iter, epochs=num_epochs, verbose=0, callbacks=[callback])\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/coraed/miniconda3/envs/d2l/lib/python3.9/site-packages/keras/layers/pooling.py\", line 357, in call\n      outputs = self.pool_function(\nNode: 'sequential_7/sequential_10/max_pooling2d_7/MaxPool'\nOOM when allocating tensor with shape[128,64,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential_7/sequential_10/max_pooling2d_7/MaxPool}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1853]"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"240.554688pt\" height=\"173.477344pt\" viewBox=\"0 0 240.554688 173.477344\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2025-04-18T15:23:45.007687</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 173.477344 \n",
       "L 240.554688 173.477344 \n",
       "L 240.554688 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 30.103125 149.599219 \n",
       "L 225.403125 149.599219 \n",
       "L 225.403125 10.999219 \n",
       "L 30.103125 10.999219 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"m45919fa687\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m45919fa687\" x=\"30.103125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(22.151563 164.197656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m45919fa687\" x=\"69.163125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(61.211563 164.197656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m45919fa687\" x=\"108.223125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(100.271563 164.197656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m45919fa687\" x=\"147.283125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(139.331563 164.197656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m45919fa687\" x=\"186.343125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(178.391563 164.197656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m45919fa687\" x=\"225.403125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(217.451563 164.197656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path id=\"m18709ae35f\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m18709ae35f\" x=\"30.103125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(7.2 153.398438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m18709ae35f\" x=\"30.103125\" y=\"121.879219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(7.2 125.678438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m18709ae35f\" x=\"30.103125\" y=\"94.159219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(7.2 97.958438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m18709ae35f\" x=\"30.103125\" y=\"66.439219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(7.2 70.238438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m18709ae35f\" x=\"30.103125\" y=\"38.719219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(7.2 42.518438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m18709ae35f\" x=\"30.103125\" y=\"10.999219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(7.2 14.798438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 30.103125 149.599219 \n",
       "L 30.103125 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 225.403125 149.599219 \n",
       "L 225.403125 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 30.103125 149.599219 \n",
       "L 225.403125 149.599219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 30.103125 10.999219 \n",
       "L 225.403125 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr, num_epochs, batch_size = 0.05, 10, 128\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)\n",
    "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a074d5c6",
   "metadata": {},
   "source": [
    "这是典型的GPU内存不足（OOM: Out of Memory）错误。错误消息显示：\n",
    "\n",
    "```\n",
    "OOM when allocating tensor with shape[128,32,112,112] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
    "```\n",
    "\n",
    "问题分析：\n",
    "1. 您使用的是NVIDIA GeForce GTX 1650显卡，只有1608MB显存\n",
    "2. 您尝试训练的模型输入大小是224×224（从`resize=224`参数可知）\n",
    "3. 批量大小设置为128，这对于您的GPU显存来说太大了\n",
    "4. 模型中的卷积层需要分配[128,32,112,112]形状的张量，超出了可用显存\n",
    "\n",
    "解决方案：\n",
    "\n",
    "1. **减小批量大小**（最直接有效）：\n",
    "   ```python\n",
    "   # 将批量大小从128减小到更小的值\n",
    "   lr, num_epochs, batch_size = 0.05, 10, 16  # 或者8、4等\n",
    "   ```\n",
    "\n",
    "2. **减小输入图像尺寸**：\n",
    "   ```python\n",
    "   # 将resize参数从224减小到更小的值\n",
    "   train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=64)  # 或更小\n",
    "   ```\n",
    "\n",
    "3. **使用混合精度训练**：\n",
    "   ```python\n",
    "   # 在代码开头添加\n",
    "   from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "   policy = mixed_precision.Policy('mixed_float16')\n",
    "   mixed_precision.set_global_policy(policy)\n",
    "   ```\n",
    "\n",
    "4. **强制使用CPU**（如果不在意训练速度）：\n",
    "   ```python\n",
    "   import os\n",
    "   os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "   # 然后修改train_ch6调用\n",
    "   d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_cpu())\n",
    "   ```\n",
    "\n",
    "建议首先尝试方案1和2的组合，将批量大小减小到16或8，并将图像尺寸减小到64或32，这通常能解决大多数OOM问题。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4594544c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.141, train acc 0.948, test acc 0.917\n",
      "1811.4 examples/sec on /GPU:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7b468eb6beb0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"183.35625pt\" viewBox=\"0 0 238.965625 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2025-04-18T15:32:10.620285</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 183.35625 \n",
       "L 238.965625 183.35625 \n",
       "L 238.965625 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 30.103125 145.8 \n",
       "L 225.403125 145.8 \n",
       "L 225.403125 7.2 \n",
       "L 30.103125 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 51.803125 145.8 \n",
       "L 51.803125 7.2 \n",
       "\" clip-path=\"url(#p03720bcbfa)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path id=\"m0236465e34\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m0236465e34\" x=\"51.803125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(48.621875 160.398438)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 95.203125 145.8 \n",
       "L 95.203125 7.2 \n",
       "\" clip-path=\"url(#p03720bcbfa)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m0236465e34\" x=\"95.203125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 4 -->\n",
       "      <g transform=\"translate(92.021875 160.398438)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 138.603125 145.8 \n",
       "L 138.603125 7.2 \n",
       "\" clip-path=\"url(#p03720bcbfa)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m0236465e34\" x=\"138.603125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 6 -->\n",
       "      <g transform=\"translate(135.421875 160.398438)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 182.003125 145.8 \n",
       "L 182.003125 7.2 \n",
       "\" clip-path=\"url(#p03720bcbfa)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m0236465e34\" x=\"182.003125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 8 -->\n",
       "      <g transform=\"translate(178.821875 160.398438)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 225.403125 145.8 \n",
       "L 225.403125 7.2 \n",
       "\" clip-path=\"url(#p03720bcbfa)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m0236465e34\" x=\"225.403125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(219.040625 160.398438)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_6\">\n",
       "     <!-- epoch -->\n",
       "     <g transform=\"translate(112.525 174.076563)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-65\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 30.103125 130.342522 \n",
       "L 225.403125 130.342522 \n",
       "\" clip-path=\"url(#p03720bcbfa)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <defs>\n",
       "       <path id=\"m2f150344e6\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2f150344e6\" x=\"30.103125\" y=\"130.342522\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(7.2 134.141741)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 30.103125 99.081007 \n",
       "L 225.403125 99.081007 \n",
       "\" clip-path=\"url(#p03720bcbfa)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2f150344e6\" x=\"30.103125\" y=\"99.081007\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(7.2 102.880225)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 30.103125 67.819491 \n",
       "L 225.403125 67.819491 \n",
       "\" clip-path=\"url(#p03720bcbfa)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2f150344e6\" x=\"30.103125\" y=\"67.819491\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(7.2 71.61871)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path d=\"M 30.103125 36.557975 \n",
       "L 225.403125 36.557975 \n",
       "\" clip-path=\"url(#p03720bcbfa)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m2f150344e6\" x=\"30.103125\" y=\"36.557975\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(7.2 40.357194)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_19\">\n",
       "    <path d=\"M 30.103125 57.941995 \n",
       "L 51.803125 110.038169 \n",
       "L 73.503125 119.067133 \n",
       "L 95.203125 124.046958 \n",
       "L 116.903125 128.097324 \n",
       "L 138.603125 131.281921 \n",
       "L 160.303125 133.586074 \n",
       "L 182.003125 136.024712 \n",
       "L 203.703125 138.168992 \n",
       "L 225.403125 139.5 \n",
       "\" clip-path=\"url(#p03720bcbfa)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_20\">\n",
       "    <path d=\"M 30.103125 44.305622 \n",
       "L 51.803125 24.251358 \n",
       "L 73.503125 20.945454 \n",
       "L 95.203125 19.158332 \n",
       "L 116.903125 17.652574 \n",
       "L 138.603125 16.368245 \n",
       "L 160.303125 15.591916 \n",
       "L 182.003125 14.805171 \n",
       "L 203.703125 14.000183 \n",
       "L 225.403125 13.5 \n",
       "\" clip-path=\"url(#p03720bcbfa)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_21\">\n",
       "    <path d=\"M 30.103125 26.554287 \n",
       "L 51.803125 22.490295 \n",
       "L 73.503125 20.661491 \n",
       "L 95.203125 20.176941 \n",
       "L 116.903125 19.754906 \n",
       "L 138.603125 18.238722 \n",
       "L 160.303125 18.144941 \n",
       "L 182.003125 18.473185 \n",
       "L 203.703125 19.926845 \n",
       "L 225.403125 18.301246 \n",
       "\" clip-path=\"url(#p03720bcbfa)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 30.103125 145.8 \n",
       "L 30.103125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 225.403125 145.8 \n",
       "L 225.403125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 30.103125 145.8 \n",
       "L 225.403125 145.8 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 30.103125 7.2 \n",
       "L 225.403125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 140.634375 100.017188 \n",
       "L 218.403125 100.017188 \n",
       "Q 220.403125 100.017188 220.403125 98.017188 \n",
       "L 220.403125 54.982812 \n",
       "Q 220.403125 52.982812 218.403125 52.982812 \n",
       "L 140.634375 52.982812 \n",
       "Q 138.634375 52.982812 138.634375 54.982812 \n",
       "L 138.634375 98.017188 \n",
       "Q 138.634375 100.017188 140.634375 100.017188 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_22\">\n",
       "     <path d=\"M 142.634375 61.08125 \n",
       "L 152.634375 61.08125 \n",
       "L 162.634375 61.08125 \n",
       "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_11\">\n",
       "     <!-- train loss -->\n",
       "     <g transform=\"translate(170.634375 64.58125)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"232.763672\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"264.550781\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"292.333984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"353.515625\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"405.615234\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_23\">\n",
       "     <path d=\"M 142.634375 75.759375 \n",
       "L 152.634375 75.759375 \n",
       "L 162.634375 75.759375 \n",
       "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_12\">\n",
       "     <!-- train acc -->\n",
       "     <g transform=\"translate(170.634375 79.259375)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"232.763672\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"264.550781\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"325.830078\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"380.810547\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_24\">\n",
       "     <path d=\"M 142.634375 90.4375 \n",
       "L 152.634375 90.4375 \n",
       "L 162.634375 90.4375 \n",
       "\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_13\">\n",
       "     <!-- test acc -->\n",
       "     <g transform=\"translate(170.634375 93.9375)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"39.208984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"100.732422\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"152.832031\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"192.041016\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"223.828125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"285.107422\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"340.087891\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p03720bcbfa\">\n",
       "   <rect x=\"30.103125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "   # 将批量大小从128减小到更小的值\n",
    "lr, num_epochs, batch_size = 0.05, 10, 16  # 或者8、4等\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=64)\n",
    "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a1c36f",
   "metadata": {
    "origin_pos": 24
   },
   "source": [
    "## 小结\n",
    "\n",
    "* VGG-11使用可复用的卷积块构造网络。不同的VGG模型可通过每个块中卷积层数量和输出通道数量的差异来定义。\n",
    "* 块的使用导致网络定义的非常简洁。使用块可以有效地设计复杂的网络。\n",
    "* 在VGG论文中，Simonyan和Ziserman尝试了各种架构。特别是他们发现深层且窄的卷积（即$3 \\times 3$）比较浅层且宽的卷积更有效。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 打印层的尺寸时，我们只看到8个结果，而不是11个结果。剩余的3层信息去哪了？\n",
    "1. 与AlexNet相比，VGG的计算要慢得多，而且它还需要更多的显存。分析出现这种情况的原因。\n",
    "1. 尝试将Fashion-MNIST数据集图像的高度和宽度从224改为96。这对实验有什么影响？\n",
    "1. 请参考VGG论文 :cite:`Simonyan.Zisserman.2014`中的表1构建其他常见模型，如VGG-16或VGG-19。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14c75e6",
   "metadata": {
    "origin_pos": 27,
    "tab": [
     "tensorflow"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/1865)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
